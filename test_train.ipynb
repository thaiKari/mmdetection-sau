{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pretrained_weights  = torch.load('./models/libra_faster_rcnn_x101_64x4d_fpn_1x_20190525-359c134a.pth')\n",
    "\n",
    "num_class = 2\n",
    "pretrained_weights['state_dict']['bbox_head.fc_cls.weight'].resize_(num_class, 1024)\n",
    "pretrained_weights['state_dict']['bbox_head.fc_cls.bias'].resize_(num_class)\n",
    "pretrained_weights['state_dict']['bbox_head.fc_reg.weight'].resize_(num_class*4, 1024)\n",
    "pretrained_weights['state_dict']['bbox_head.fc_reg.bias'].resize_(num_class*4)\n",
    "\n",
    "torch.save(pretrained_weights, \"./models/libra_faster_rcnn_x101_64x4d_fpn_1x_%d.pth\"%num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from mmcv import Config\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import (get_root_logger, init_dist, set_random_seed,\n",
    "                        train_detector)\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/01_faster_rcnn_r50_fpn_1x-SAU.py'\n",
    "work_dir='work_dirs/a01_20191021'\n",
    "#checkpoint_file = 'checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth'\n",
    "gpus = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thaikari/anaconda3/bin/python: Error while finding module specification for 'torch.distributed.launch' (ModuleNotFoundError: No module named 'torch')\r\n"
     ]
    }
   ],
   "source": [
    "## RUN in cmd to get mAP and validation. Distributed!\n",
    "\n",
    "./tools/dist_train.sh ${CONFIG_FILE} ${GPU_NUM} [optional arguments]\n",
    "\n",
    "--validate (strongly recommended): Perform evaluation at every k (default value is 1, which can be modified like this) epochs during the training.\n",
    "--work_dir ${WORK_DIR}: Override the working directory specified in the config file.\n",
    "--resume_from ${CHECKPOINT_FILE}: Resume from a previous checkpoint file.\n",
    "   \n",
    "./tools/dist_train.sh 'configs/05_faster_rcnn_r50_fpn_1x-SAU.py' 2 --validate --work_dir 'work_dirs/20191022_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS fails to launch distributed...\n",
    "def train(config,\n",
    "          gpus,\n",
    "          autoscale_lr=False,\n",
    "          launcher='pytorch',\n",
    "          local_rank=0,\n",
    "          resume_from=None,\n",
    "          seed=None,\n",
    "          validate=False,\n",
    "          work_dir=None):\n",
    "    \n",
    "    \n",
    "    cfg = Config.fromfile(config_file)\n",
    "    # set cudnn_benchmark\n",
    "    if cfg.get('cudnn_benchmark', False):\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    # update configs according to CLI args\n",
    "    if work_dir is not None:\n",
    "        cfg.work_dir = work_dir\n",
    "    if resume_from is not None:\n",
    "        cfg.resume_from = resume_from\n",
    "    cfg.gpus = gpus\n",
    "\n",
    "    if autoscale_lr:\n",
    "        # apply the linear scaling rule (https://arxiv.org/abs/1706.02677)\n",
    "        cfg.optimizer['lr'] = cfg.optimizer['lr'] * cfg.gpus / 8\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    if launcher == 'none':\n",
    "        distributed = False\n",
    "    else:\n",
    "        distributed = True\n",
    "        init_dist(launcher, **cfg.dist_params)\n",
    "\n",
    "    # init logger before other steps\n",
    "    logger = get_root_logger(cfg.log_level)\n",
    "    logger.info('Distributed training: {}'.format(distributed))\n",
    "\n",
    "    # set random seeds\n",
    "    if seed is not None:\n",
    "        logger.info('Set random seed to {}'.format(seed))\n",
    "        set_random_seed(seed)\n",
    "\n",
    "    model = build_detector(\n",
    "        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "    datasets = [build_dataset(cfg.data.train)]\n",
    "    if len(cfg.workflow) == 2:\n",
    "        datasets.append(build_dataset(cfg.data.val))\n",
    "    if cfg.checkpoint_config is not None:\n",
    "        # save mmdet version, config file content and class names in\n",
    "        # checkpoints as meta data\n",
    "        cfg.checkpoint_config.meta = dict(\n",
    "            mmdet_version=__version__,\n",
    "            config=cfg.text,\n",
    "            CLASSES=datasets[0].CLASSES)\n",
    "    # add an attribute for visualization convenience\n",
    "    model.CLASSES = datasets[0].CLASSES\n",
    "    print('=====================')\n",
    "    print('VALIDATE', validate)\n",
    "    train_detector(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=distributed,\n",
    "        validate=validate,\n",
    "        logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RANK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1e72ac2fb96e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwork_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'work_dirs/a00_20191021'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-83dca5efad61>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, gpus, autoscale_lr, launcher, local_rank, resume_from, seed, validate, work_dir)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdistributed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0minit_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# init logger before other steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mmdetection/mmdet/apis/env.py\u001b[0m in \u001b[0;36minit_dist\u001b[0;34m(launcher, backend, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlauncher\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0m_init_dist_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlauncher\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mpi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0m_init_dist_mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mmdetection/mmdet/apis/env.py\u001b[0m in \u001b[0;36m_init_dist_pytorch\u001b[0;34m(backend, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_init_dist_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# TODO: use local_rank instead of rank % num_gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RANK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mnum_gpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RANK'"
     ]
    }
   ],
   "source": [
    "train(config_file, gpus, work_dir='work_dirs/a00_20191021', validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IN config file:\n",
    "\n",
    "#Change lr => 0.0005 from 0.02 because 2gpus instead of 8 gpus\n",
    "#start_from = checkpoint_file\n",
    "#frozen_stages = 3 (from 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#for param in model.parameters(): # Freeze all parameters\\n\",\n",
    "#    param.requires_grad = False\n",
    "    \n",
    "#for param in model.fc.parameters(): # Unfreeze the last fully - connected\n",
    "#    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(config_file)\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "datasets[0].CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python mmlab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
